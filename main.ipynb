{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Convex_Area  \\\n",
      "0  56276    888.242           326.1485           220.2388        56831   \n",
      "1  76631   1068.146           417.1932           234.2289        77280   \n",
      "2  71623   1082.987           435.8328           211.0457        72663   \n",
      "3  66458    992.051           381.5638           222.5322        67118   \n",
      "4  66107    998.146           383.8883           220.4545        67117   \n",
      "\n",
      "   Equiv_Diameter  Eccentricity  Solidity  Extent  Roundness  Aspect_Ration  \\\n",
      "0        267.6805        0.7376    0.9902  0.7453     0.8963         1.4809   \n",
      "1        312.3614        0.8275    0.9916  0.7151     0.8440         1.7811   \n",
      "2        301.9822        0.8749    0.9857  0.7400     0.7674         2.0651   \n",
      "3        290.8899        0.8123    0.9902  0.7396     0.8486         1.7146   \n",
      "4        290.1207        0.8187    0.9850  0.6752     0.8338         1.7413   \n",
      "\n",
      "   Compactness       Class  \n",
      "0       0.8207  erevelik  \n",
      "1       0.7487  erevelik  \n",
      "2       0.6929  erevelik  \n",
      "3       0.7624  erevelik  \n",
      "4       0.7557  erevelik  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('pumpkin_seeds.csv', encoding='latin1')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the class names to its appropriate name. This error occured due to the different characters that csv read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cercevelik' 'Urgup Sivrisi']\n"
     ]
    }
   ],
   "source": [
    "unique_class_values = df['Class'].unique()\n",
    "\n",
    "class_mapping = {\n",
    "    unique_class_values[0]: 'Cercevelik',\n",
    "    unique_class_values[1]: 'Urgup Sivrisi'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Class' column\n",
    "df['Class'] = df['Class'].map(class_mapping)\n",
    "\n",
    "# Verify the changes\n",
    "print(df['Class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Convex_Area  \\\n",
      "0  56276    888.242           326.1485           220.2388        56831   \n",
      "1  76631   1068.146           417.1932           234.2289        77280   \n",
      "2  71623   1082.987           435.8328           211.0457        72663   \n",
      "3  66458    992.051           381.5638           222.5322        67118   \n",
      "4  66107    998.146           383.8883           220.4545        67117   \n",
      "\n",
      "   Equiv_Diameter  Eccentricity  Solidity  Extent  Roundness  Aspect_Ration  \\\n",
      "0        267.6805        0.7376    0.9902  0.7453     0.8963         1.4809   \n",
      "1        312.3614        0.8275    0.9916  0.7151     0.8440         1.7811   \n",
      "2        301.9822        0.8749    0.9857  0.7400     0.7674         2.0651   \n",
      "3        290.8899        0.8123    0.9902  0.7396     0.8486         1.7146   \n",
      "4        290.1207        0.8187    0.9850  0.6752     0.8338         1.7413   \n",
      "\n",
      "   Compactness       Class  \n",
      "0       0.8207  Cercevelik  \n",
      "1       0.7487  Cercevelik  \n",
      "2       0.6929  Cercevelik  \n",
      "3       0.7624  Cercevelik  \n",
      "4       0.7557  Cercevelik  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Libraries to be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Area    Perimeter  Major_Axis_Length  Minor_Axis_Length  \\\n",
      "count    2500.000000  2500.000000        2500.000000        2500.000000   \n",
      "mean    80658.220800  1130.279015         456.601840         225.794921   \n",
      "std     13664.510228   109.256418          56.235704          23.297245   \n",
      "min     47939.000000   868.485000         320.844600         152.171800   \n",
      "25%     70765.000000  1048.829750         414.957850         211.245925   \n",
      "50%     79076.000000  1123.672000         449.496600         224.703100   \n",
      "75%     89757.500000  1203.340500         492.737650         240.672875   \n",
      "max    136574.000000  1559.450000         661.911300         305.818000   \n",
      "\n",
      "         Convex_Area  Equiv_Diameter  Eccentricity     Solidity       Extent  \\\n",
      "count    2500.000000     2500.000000   2500.000000  2500.000000  2500.000000   \n",
      "mean    81508.084400      319.334230      0.860879     0.989492     0.693205   \n",
      "std     13764.092788       26.891920      0.045167     0.003494     0.060914   \n",
      "min     48366.000000      247.058400      0.492100     0.918600     0.468000   \n",
      "25%     71512.000000      300.167975      0.831700     0.988300     0.658900   \n",
      "50%     79872.000000      317.305350      0.863700     0.990300     0.713050   \n",
      "75%     90797.750000      338.057375      0.897025     0.991500     0.740225   \n",
      "max    138384.000000      417.002900      0.948100     0.994400     0.829600   \n",
      "\n",
      "         Roundness  Aspect_Ration  Compactness  \n",
      "count  2500.000000    2500.000000  2500.000000  \n",
      "mean      0.791533       2.041702     0.704121  \n",
      "std       0.055924       0.315997     0.053067  \n",
      "min       0.554600       1.148700     0.560800  \n",
      "25%       0.751900       1.801050     0.663475  \n",
      "50%       0.797750       1.984200     0.707700  \n",
      "75%       0.834325       2.262075     0.743500  \n",
      "max       0.939600       3.144400     0.904900  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features and target\n",
    "features = df[['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Eccentricity', 'Roundness']]\n",
    "target = df['Class']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "knn_predictions = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_scaled, y_train)\n",
    "nb_predictions = nb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_predictions = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy: 0.8626666666666667\n",
      "Naive Bayes Accuracy: 0.836\n",
      "Logistic Regression Accuracy: 0.8546666666666667\n",
      "\n",
      "kNN Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Cercevelik       0.87      0.87      0.87       390\n",
      "Urgup Sivrisi       0.86      0.85      0.86       360\n",
      "\n",
      "     accuracy                           0.86       750\n",
      "    macro avg       0.86      0.86      0.86       750\n",
      " weighted avg       0.86      0.86      0.86       750\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Cercevelik       0.83      0.86      0.84       390\n",
      "Urgup Sivrisi       0.84      0.81      0.83       360\n",
      "\n",
      "     accuracy                           0.84       750\n",
      "    macro avg       0.84      0.84      0.84       750\n",
      " weighted avg       0.84      0.84      0.84       750\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Cercevelik       0.85      0.87      0.86       390\n",
      "Urgup Sivrisi       0.86      0.84      0.85       360\n",
      "\n",
      "     accuracy                           0.85       750\n",
      "    macro avg       0.85      0.85      0.85       750\n",
      " weighted avg       0.85      0.85      0.85       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the models\n",
    "print(\"kNN Accuracy:\", accuracy_score(y_test, knn_predictions))\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_predictions))\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nkNN Classification Report:\\n\", classification_report(y_test, knn_predictions))\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, lr_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
